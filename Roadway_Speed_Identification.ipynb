{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a6f66a",
   "metadata": {},
   "source": [
    "# Roadway and Speed Identification from Satellite Images  \n",
    "\n",
    "This notebook is a stream-lined version of the AWS Tutorial: [Deep Learning on AWS Open Data Registry: Automatic Building and Road Extraction from Satellite and LiDAR](https://github.com/aws-samples/aws-open-data-satellite-lidar-tutorial). In addition to simplifying the code, we also explore the business value of such a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d8222",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978728a",
   "metadata": {},
   "source": [
    "After cell finishes, change Kernel to \"conda_tutorial_env\" (may need to wait a bit and refresh page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./setup-env.sh tutorial_env\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16222b77",
   "metadata": {},
   "source": [
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fea80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, json, random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import torch\n",
    "from torch import nn\n",
    "import networkx as nx\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edf8f9",
   "metadata": {},
   "source": [
    "The below package was customized by AWS and updated by us for this tutorial. Additional information is available in the libs folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5567ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import libs.solaris as sol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f89317",
   "metadata": {},
   "source": [
    "#### Plotting Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "689534e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498bf81",
   "metadata": {},
   "source": [
    "## Download Data from S3  \n",
    "This tutorial uses  S3 bucket is publically available to all and in an S3 bucket hosted by Amazon. In total, the data download is more than 60GB large, so the notebook much have a volume size at least that large.  \n",
    "\n",
    "The dataset is satellite images from around Las Vegas. In addition to the satellite photos, there is Lidar image data which indicates height of objects on the Earth and different materials based on how laser light is reflected back from the surface. The reflectivity of road surfaces is different from the surrounding surfaces, which we will use in our model. The labeled data is a mask of road map data that is color coded based on the speed limit on that portion of the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d365a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./download-from-s3.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef3f550",
   "metadata": {},
   "source": [
    "## Example Plots of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72554b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/roads/'\n",
    "img_dir = os.path.join(data_dir, 'RGB+INTEN')\n",
    "mask_dir = os.path.join(data_dir, 'mask_roads_speed')\n",
    "mask_mc_dir = os.path.join(data_dir, 'mask_roads_speed_mc')\n",
    "\n",
    "prefix = 'SN3_roads_train_AOI_2_Vegas_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af931169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road plotting parameters\n",
    "speed_colors = [36, 72, 108, 144, 180, 216, 252]\n",
    "speed_names = ['1-10 mph','11-20 mph','21-30 mph','31-40 mph','41-50 mph','51-60 mph','61-65 mph','full map']\n",
    "road_mask_params = {'vmin': 0, 'vmax': 255, 'cmap': 'YlOrRd', 'interpolation': 'none'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'img1136'\n",
    "\n",
    "# Read in 4-channel image from GeoTIFF.\n",
    "img_file = prefix + 'RGB+INTEN_' + sample + '.tif'\n",
    "img_path = os.path.join(img_dir, img_file)\n",
    "img = skimage.io.imread(img_path)\n",
    "rgb = img[..., :3]\n",
    "inten = img[..., -1]\n",
    "\n",
    "# Read in road mask images. Note that these masks were binned\n",
    "# into multiple speed bins. In this case, there are 7 categories.\n",
    "mask_file = img_file.replace('RGB+INTEN', 'mask_roads_speed')\n",
    "mask_path = os.path.join(mask_dir, mask_file)\n",
    "mask = skimage.io.imread(mask_path)\n",
    "\n",
    "# Display satellite image and road mask.\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(rgb)\n",
    "ax[0].set_title('Satellite image')\n",
    "ax[1].imshow(inten, cmap='gray', vmin=0, vmax=5000)\n",
    "ax[1].set_title('LiDAR intensity')\n",
    "ax[2].imshow(mask, alpha=(mask>0).astype('float'), **road_mask_params)\n",
    "ax[2].set_title('Road mask (color as speed)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6cb1c",
   "metadata": {},
   "source": [
    "The road network mask is further broken down into the portions of the network in each of the 7 speed limit categories. They are displayed below, along with the whole map in the 8th subplot. This binary mask is actually what is used as the labeled data by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f18d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_mc_file = img_file.replace('RGB+INTEN', 'mask_roads_speed_mc')\n",
    "mask_mc_path = os.path.join(mask_mc_dir, mask_mc_file)\n",
    "mask_mc = skimage.io.imread(mask_mc_path)\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(8, 4))\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.05, hspace=0.15)\n",
    "for i in range(mask_mc.shape[-1]):\n",
    "    row = i // ax.shape[-1]\n",
    "    col = i % ax.shape[-1]\n",
    "    subax = ax[row][col]\n",
    "    \n",
    "    submask = mask_mc[..., i]\n",
    "    subax.imshow(submask, cmap='gray_r')\n",
    "    \n",
    "    plt.setp(subax.get_yticklabels(), visible=False)\n",
    "    plt.setp(subax.get_xticklabels(), visible=False)\n",
    "    subax.set_title(label=speed_names[i])\n",
    "    subax.tick_params(axis='both', which='both', length=0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c27e8",
   "metadata": {},
   "source": [
    "## Road Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab9ced",
   "metadata": {},
   "source": [
    "To predict the locations of roads and their speeds, the model will use the RGB values from the satellite images and the values from the Lidar images as the input data. The ground truth the model is trying to predict is the roadway map with color-coded speed values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361041d",
   "metadata": {},
   "source": [
    "Amazon provides a pre-trained ResNet-Unet CNN for those using smaller Sagemaker notebook instances. It takes significant resources to train from scratch, so only those on a GPU-enabled instance should train from scratch. **Skip to the next section to use the saved model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb4e10",
   "metadata": {},
   "source": [
    "### To Train a New Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists of training image/label files.\n",
    "img_file_list = [f for f in os.listdir(img_dir) if f.endswith('.tif')]\n",
    "mask_mc_file_list = [f for f in os.listdir(mask_mc_dir) if f.endswith('.tif')]\n",
    "img_path_list = [os.path.join(img_dir, f) for f in img_file_list]\n",
    "mask_mc_path_list = [os.path.join(mask_mc_dir, f) for f in mask_mc_file_list]\n",
    "assert len(img_path_list) == len(mask_mc_path_list)\n",
    "\n",
    "# Sort the list by filenames.\n",
    "img_path_list.sort()\n",
    "mask_mc_path_list.sort()\n",
    "\n",
    "# Create Pandas data frame, containing columns 'image' and 'label'.\n",
    "total_df = pd.DataFrame({'image': img_path_list,\n",
    "                         'label': mask_mc_path_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b92b3",
   "metadata": {},
   "source": [
    "##### Create Training and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split this data frame to training data and blind test data.\n",
    "split_mask = np.random.rand(len(total_df)) < 0.7\n",
    "train_df = total_df[split_mask]\n",
    "test_df = total_df[~split_mask]\n",
    "\n",
    "# Save datasets to csv\n",
    "train_csv_path = './data/roads/train_data.csv'\n",
    "test_csv_path = './data/roads/test_data.csv'\n",
    "train_df.to_csv(train_csv_path)\n",
    "test_df.to_csv(test_csv_path)\n",
    "\n",
    "print('{} images in total, {} - train, {} - test.'.format(\n",
    "    len(total_df), len(train_df), len(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e8b611",
   "metadata": {},
   "source": [
    "##### Create Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = sol.utils.config.parse('RGB+INTEN.yml')\n",
    "config['training_data_csv'] = train_csv_path\n",
    "config['inference_data_csv'] = test_csv_path\n",
    "\n",
    "# Load customized multi-channel input ResNet-Unet model.\n",
    "from networks.resnet_unet import get_modified_resnet_unet\n",
    "\n",
    "model = get_modified_resnet_unet(in_channels=config['data_specs']['channels'], logits=True) # Output logits instead of sigmoid/softmax\n",
    "model_dict = {\n",
    "    'model_name': 'modified_resnet_unet',\n",
    "    'weight_path': None,\n",
    "    'weight_url': None,\n",
    "    'arch': model\n",
    "}\n",
    "\n",
    "# Create trainer\n",
    "trained_model = sol.nets.train.Trainer(config, custom_model_dict=model_dict)\n",
    "\n",
    "# Show model architecture\n",
    "print(trained_model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457a0a0",
   "metadata": {},
   "source": [
    "##### Train the Model (**ONLY RUN WITH APPROPRIATE RESOURCES**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cada54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0454a5e3",
   "metadata": {},
   "source": [
    "### To Load the Pre-Trained Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb161926",
   "metadata": {},
   "source": [
    "##### Load the Model with Pre-Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = sol.utils.config.parse('RGB+INTEN.yml')\n",
    "\n",
    "# Load customized multi-channel input ResNet-Unet model.\n",
    "from networks.resnet_unet import get_modified_resnet_unet\n",
    "\n",
    "model = get_modified_resnet_unet(in_channels=config['data_specs']['channels'], logits=False) # Output sigmoid (0-1 value)\n",
    "model_dict = {\n",
    "    'model_name': 'modified_resnet_unet',\n",
    "    'weight_path': config['training']['model_dest_path'],\n",
    "    'weight_url': None,\n",
    "    'arch': model\n",
    "}\n",
    "config['train'] = False\n",
    "\n",
    "######## UNCOMMENT IF LOW RAM ########\n",
    "# MAKE SMALLER, MAY REDUCE ACCURACY ##\n",
    "config['batch_size'] = 1\n",
    "config['data_specs']['width'] = 736\n",
    "config['data_specs']['height'] = 736\n",
    "######################################\n",
    "\n",
    "trained_model = sol.nets.infer.Inferer(config, custom_model_dict=model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7316351a",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13430816",
   "metadata": {},
   "source": [
    "##### Image of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'img1300'\n",
    "\n",
    "img_file = prefix + 'RGB+INTEN_' + sample + '.tif'\n",
    "img_path = os.path.join(img_dir, img_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33cfb2",
   "metadata": {},
   "source": [
    "##### Predict Image of Interest (automatically saved in output directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e938eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame({'image': [img_path]})\n",
    "trained_model(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d5cd3",
   "metadata": {},
   "source": [
    "##### Batch Predict All Images (automatically saved in output directory) - will take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a836d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if trained new model\n",
    "# trained_model(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db00db",
   "metadata": {},
   "source": [
    "##### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data\n",
    "img = skimage.io.imread(img_path)\n",
    "rgb = img[..., :3]\n",
    "inten = img[..., -1]\n",
    "\n",
    "# Load ground truth\n",
    "mask_file = img_file.replace('RGB+INTEN', 'mask_roads_speed')\n",
    "mask_path = os.path.join(mask_dir, mask_file)\n",
    "mask = skimage.io.imread(mask_path)\n",
    "\n",
    "# Load prediction result from the output directory\n",
    "pred_file = img_file # same name as input image file\n",
    "pred_dir = config['inference']['output_dir']\n",
    "pred_path = os.path.join(pred_dir, pred_file)\n",
    "pred = skimage.io.imread(pred_path)\n",
    "\n",
    "# Prepare for multi-class visualization\n",
    "pred_class = np.argmax(pred[..., :-1], axis=-1) # discard the last aggregated channel\n",
    "pred_color = np.array(speed_colors)[pred_class]\n",
    "pred_alpha = pred[..., -1] # aggregated likelihood as alpha\n",
    "\n",
    "# Display satellite image, LiDAR, prediction mask, and ground truth mask.\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax[0][0].imshow(rgb)\n",
    "ax[0][0].set_title('Satellite image')\n",
    "ax[0][1].imshow(inten, cmap='gray', vmin=0, vmax=5000)\n",
    "ax[0][1].set_title('LiDAR intensity')\n",
    "ax[1][0].imshow(pred_color, alpha=pred_alpha, **road_mask_params)\n",
    "ax[1][0].set_title('Predicted map (color as speed)')\n",
    "ax[1][1].imshow(mask, alpha=(mask>0).astype('float'), **road_mask_params)\n",
    "ax[1][1].set_title('Ground truth (color as speed)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f7d6f",
   "metadata": {},
   "source": [
    "### End of Demo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tutorial_env",
   "language": "python",
   "name": "conda_tutorial_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
